"""
VIBE MATCHER PROTOTYPE
INTRODUCTION:
Why AI at Nexora?
AI-powered recommendation systems represent the future of personalized retail experiences.
At Nexora, I see an opportunity to leverage semantic understanding through embeddings to move
beyond traditional collaborative filtering. This prototype demonstrates how natural language
processing can bridge the gap between how customers *feel* about fashion and what products
match those vibes, creating more intuitive and emotionally resonant shopping experiences.
"""
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple
import time
import warnings
warnings.filterwarnings('ignore')

import openai
import os  

openai.api_key = os.getenv("OPENAI_API_KEY")

fashion_data = {
    'product_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'name': [
        'Boho Maxi Dress',
        'Urban Leather Jacket',
        'Cozy Cashmere Sweater',
        'Minimalist White Sneakers',
        'Vibrant Festival Top',
        'Classic Denim Jeans',
        'Elegant Silk Blouse',
        'Sporty Track Pants',
        'Vintage Floral Skirt',
        'Edgy Metal Chain Belt'
    ],
    'description': [
        'Flowy maxi dress with earthy tones and bohemian prints, perfect for music festivals and beach vibes',
        'Sleek black leather jacket with silver zippers, embodying urban street style and edgy sophistication',
        'Ultra-soft cashmere sweater in warm beige, ideal for cozy winter evenings and comfortable elegance',
        'Clean white sneakers with minimalist design, versatile for casual everyday urban wear',
        'Bold tie-dye crop top with energetic colors, designed for festival season and vibrant self-expression',
        'Timeless medium-wash denim jeans with comfortable fit, a versatile wardrobe staple for any occasion',
        'Sophisticated silk blouse in champagne color, elegant and refined for professional or formal settings',
        'Athletic jogger-style track pants with moisture-wicking fabric, perfect for active lifestyles and gym sessions',
        'Romantic floral midi skirt with vintage-inspired patterns, feminine and nostalgic aesthetic',
        'Statement metal chain belt with industrial aesthetic, adding bold edge to any minimalist outfit'
    ],
    'price': [89.99, 249.99, 179.99, 79.99, 45.99, 69.99, 129.99, 54.99, 65.99, 39.99],
    'category': [
        'Dresses', 'Outerwear', 'Tops', 'Shoes', 'Tops',
        'Bottoms', 'Tops', 'Bottoms', 'Bottoms', 'Accessories'
    ],
    'vibe_tags': [
        ['boho', 'festival', 'relaxed', 'earthy'],
        ['edgy', 'urban', 'sophisticated', 'cool'],
        ['cozy', 'elegant', 'comfort', 'winter'],
        ['minimalist', 'casual', 'versatile', 'clean'],
        ['energetic', 'vibrant', 'festival', 'bold'],
        ['classic', 'versatile', 'casual', 'timeless'],
        ['elegant', 'sophisticated', 'formal', 'refined'],
        ['sporty', 'active', 'athletic', 'comfortable'],
        ['vintage', 'romantic', 'feminine', 'nostalgic'],
        ['edgy', 'bold', 'statement', 'industrial']
    ]
}

df_products = pd.DataFrame(fashion_data)

print("Fashion Product Catalog Created:")
print(f"Total Products: {len(df_products)}")
print(f"\nSample Products:")
print(df_products[['name', 'price', 'category']].head(3))
print(f"\nVibe Tag Examples:")
for idx in [0, 1, 4]:
    print(f"  ‚Ä¢ {df_products.loc[idx, 'name']}: {df_products.loc[idx, 'vibe_tags']}")

print("\n" + "="*60)
print("PART 2: EMBEDDINGS GENERATION")
print("="*60 + "\n")

def get_embedding(text: str, model: str = "text-embedding-ada-002") -> List[float]:
    """
    Generate embedding for given text using OpenAI API.
    
    Args:
        text: Input text to embed
        model: OpenAI embedding model name
    
    Returns:
        List of embedding values
    """
    try:
        text = text.replace("\n", " ")
        response = openai.Embedding.create(input=[text], model=model)
        return response['data'][0]['embedding']
    except Exception as e:
        print(f"‚ö†Ô∏è  Error generating embedding: {e}")
        print("Note: Make sure to set your OpenAI API key above!")
        return np.random.rand(1536).tolist()

def generate_product_embeddings(df: pd.DataFrame) -> pd.DataFrame:
    """
    Generate embeddings for all products in the dataframe.
    
    Args:
        df: DataFrame with product descriptions
    
    Returns:
        DataFrame with added 'embedding' column
    """
    print("Generating embeddings for product descriptions...")
    embeddings = []
    
    for idx, row in df.iterrows():
        print(f"  Processing {idx+1}/{len(df)}: {row['name']}")
        embedding = get_embedding(row['description'])
        embeddings.append(embedding)
        time.sleep(0.1)  
    
    df['embedding'] = embeddings
    print(f"\n‚úì Generated {len(embeddings)} embeddings")
    print(f"  Embedding dimension: {len(embeddings[0])}")
    return df

print("‚ö†Ô∏è  Using random embeddings for demo (set API key for real embeddings)")
df_products['embedding'] = [np.random.rand(1536).tolist() for _ in range(len(df_products))]
print(f"‚úì Created {len(df_products)} product embeddings")

test_queries = [
    "energetic urban chic",
    "cozy comfortable winter style",
    "bold statement festival outfit"
]

print(f"\nTest Queries Prepared: {len(test_queries)}")
for i, q in enumerate(test_queries, 1):
    print(f"  {i}. '{q}'")

print("\n" + "="*60)
print("PART 3: VECTOR SEARCH & SIMILARITY MATCHING")
print("="*60 + "\n")

def compute_similarity_scores(
    query_embedding: List[float],
    product_embeddings: np.ndarray
) -> np.ndarray:
    """
    Compute cosine similarity between query and all products.
    
    Args:
        query_embedding: Embedding vector for the query
        product_embeddings: Matrix of product embeddings
    
    Returns:
        Array of similarity scores
    """
    query_vec = np.array(query_embedding).reshape(1, -1)
    similarities = cosine_similarity(query_vec, product_embeddings)[0]
    return similarities

def get_top_matches(
    query: str,
    df: pd.DataFrame,
    top_k: int = 3,
    threshold: float = 0.7
) -> Tuple[pd.DataFrame, float]:
    """
    Find top-k matching products for a given vibe query.
    
    Args:
        query: Natural language vibe query
        df: DataFrame with products and embeddings
        top_k: Number of top matches to return
        threshold: Minimum similarity score for "good" match
    
    Returns:
        Tuple of (results DataFrame, query_time)
    """
    start_time = time.time()
    
    print(f"Query: '{query}'")
    query_embedding = get_embedding(query)
    
    product_embeddings = np.array(df['embedding'].tolist())
    
    similarities = compute_similarity_scores(query_embedding, product_embeddings)
    
    df_results = df.copy()
    df_results['similarity_score'] = similarities
    df_results = df_results.sort_values('similarity_score', ascending=False)
    
    top_matches = df_results.head(top_k)
    
    query_time = time.time() - start_time
    
    max_score = top_matches['similarity_score'].max()
    if max_score < threshold:
        print(f"‚ö†Ô∏è  Warning: Best match score ({max_score:.3f}) below threshold ({threshold})")
        print(f"   Fallback: Consider broadening search or showing diverse options")
    
    return top_matches, query_time

def display_recommendations(results: pd.DataFrame, query: str):
    """
    Display recommendation results in a formatted way.
    
    Args:
        results: DataFrame with top matching products
        query: Original query string
    """
    print(f"\n{'='*60}")
    print(f"TOP 3 MATCHES FOR: '{query}'")
    print(f"{'='*60}\n")
    
    for idx, (_, row) in enumerate(results.iterrows(), 1):
        score = row['similarity_score']
        quality = "Excellent" if score > 0.85 else "Good" if score > 0.7 else "Fair"
        
        print(f"#{idx} | {row['name']}")
        print(f"     Score: {score:.4f} ({quality} match)")
        print(f"     Price: ${row['price']}")
        print(f"     Vibes: {', '.join(row['vibe_tags'][:3])}")
        print(f"     {row['description'][:100]}...")
        print()

print("\n" + "="*60)
print("PART 4: TESTING & EVALUATION")
print("="*60 + "\n")

results_log = []
latencies = []

for query in test_queries:
    print(f"\n{'‚îÄ'*60}")
    results, query_time = get_top_matches(query, df_products, top_k=3, threshold=0.7)
    display_recommendations(results, query)
    
    avg_score = results['similarity_score'].mean()
    results_log.append({
        'query': query,
        'avg_similarity': avg_score,
        'top_score': results['similarity_score'].max(),
        'latency_ms': query_time * 1000,
        'good_matches': (results['similarity_score'] > 0.7).sum()
    })
    latencies.append(query_time * 1000)
    
    print(f"Metrics: Avg Score={avg_score:.3f} | Latency={query_time*1000:.1f}ms")

df_metrics = pd.DataFrame(results_log)

print("\n" + "="*60)
print("EVALUATION SUMMARY")
print("="*60 + "\n")
print(df_metrics.to_string(index=False))

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].bar(range(len(test_queries)), df_metrics['avg_similarity'], 
            color='skyblue', edgecolor='navy', alpha=0.7)
axes[0].axhline(y=0.7, color='red', linestyle='--', label='Good Match Threshold')
axes[0].set_xlabel('Query Index')
axes[0].set_ylabel('Average Similarity Score')
axes[0].set_title('Matching Quality by Query')
axes[0].legend()
axes[0].set_xticks(range(len(test_queries)))
axes[0].grid(axis='y', alpha=0.3)

axes[1].plot(range(len(latencies)), latencies, marker='o', 
             linewidth=2, markersize=8, color='coral')
axes[1].set_xlabel('Query Index')
axes[1].set_ylabel('Latency (ms)')
axes[1].set_title('Query Response Time')
axes[1].grid(True, alpha=0.3)
axes[1].set_xticks(range(len(test_queries)))

plt.tight_layout()
plt.savefig('vibe_matcher_metrics.png', dpi=150, bbox_inches='tight')
print("\n‚úì Metrics visualization saved as 'vibe_matcher_metrics.png'")
plt.show()

print(f"\nPerformance Statistics:")
print(f"  ‚Ä¢ Average Similarity: {df_metrics['avg_similarity'].mean():.3f}")
print(f"  ‚Ä¢ Average Latency: {df_metrics['latency_ms'].mean():.1f}ms")
print(f"  ‚Ä¢ Good Matches (>0.7): {df_metrics['good_matches'].sum()}/{len(test_queries)*3}")

print("\n" + "="*60)
print("PART 5: EDGE CASE TESTING")
print("="*60 + "\n")

edge_cases = [
    ("extremely specific rare query xyz123", "No semantic match expected"),
    ("", "Empty query handling"),
    ("elegant sophisticated formal", "Multiple good matches expected")
]

print("Testing edge cases:\n")
for edge_query, expected in edge_cases:
    if edge_query == "":
        print(f"Case: Empty string ‚Üí Skipped (requires fallback prompt)")
        print(f"  Expected: {expected}\n")
        continue
    
    try:
        results, _ = get_top_matches(edge_query, df_products, top_k=3, threshold=0.7)
        max_score = results['similarity_score'].max()
        print(f"Case: '{edge_query}'")
        print(f"  Expected: {expected}")
        print(f"  Result: Max score = {max_score:.3f}")
        print(f"  Status: {'‚úì Handled' if max_score > 0 else '‚ö†Ô∏è Needs fallback'}\n")
    except Exception as e:
        print(f"Case: '{edge_query}'")
        print(f"  Error: {e}")
        print(f"  Status: ‚ö†Ô∏è Needs error handling\n")

print("\n" + "="*60)
print("PART 6: REFLECTION & NEXT STEPS")
print("="*60 + "\n")

reflection = """
KEY LEARNINGS & IMPROVEMENTS:

1. **Vector Database Integration (Pinecone/Weaviate)**
   - Current: In-memory numpy arrays, O(n) search complexity
   - Improvement: Migrate to Pinecone for sub-millisecond ANN search at scale
   - Impact: Support 100K+ products with <50ms latency

2. **Hybrid Search Enhancement**
   - Current: Pure semantic similarity via embeddings
   - Improvement: Combine with keyword filters (price, category, availability)
   - Impact: Better user control and business constraint satisfaction

3. **Multi-Modal Embeddings**
   - Current: Text-only descriptions
   - Improvement: Integrate CLIP for image+text embeddings
   - Impact: "Show me outfits like this photo" queries become possible

4. **Dynamic Threshold Adaptation**
   - Current: Fixed 0.7 threshold across all queries
   - Improvement: Query-dependent thresholds based on embedding confidence
   - Impact: Fewer false positives, better fallback UX

5. **Real-Time Personalization**
   - Current: Static product embeddings
   - Improvement: User profile embeddings + collaborative filtering fusion
   - Impact: "Vibe + You" recommendations (e.g., boho style adjusted for past purchases)

EDGE CASES HANDLED:
‚úì Low similarity scores ‚Üí Warning + fallback suggestion
‚úì Query latency monitoring ‚Üí Performance optimization opportunities identified
‚úì Diverse vibe queries ‚Üí System adapts to different semantic spaces

PRODUCTION CONSIDERATIONS:
- Embedding cache strategy (TTL, invalidation on catalog updates)
- A/B testing framework for threshold tuning
- Explainability: "Why this match?" via attention on vibe tags
- Cold start: Bootstrap embeddings for new products (GPT-4 synthetic descriptions)
"""

print(reflection)

print("\nüéØ TRY IT YOURSELF:")
user_query = input("Enter your vibe query: ")
results, _ = get_top_matches(user_query, df_products)
display_recommendations(results, user_query)